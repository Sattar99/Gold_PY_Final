{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required Modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the dataset as a Pandas Dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"superstore.csv\")\n",
    "tempdf=df.copy()\n",
    "coor= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_columns = coor.select_dtypes(include=['float64','int64','int32']).columns\n",
    "categorical_columns = coor.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Calculate correlation matrix for numerical columns\n",
    "numerical_corr = coor[numerical_columns].corr()\n",
    "\n",
    "# Calculate correlation matrix for categorical columns\n",
    "#categorical_corr = tempdf[categorical_columns].corr()\n",
    "\n",
    "# Print correlation matrices\n",
    "print(\"Correlation Matrix for Numerical Columns:\")\n",
    "numerical_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_columns = coor.select_dtypes(include=['float64','int64','int32']).columns\n",
    "categorical_columns = coor.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Calculate correlation matrix for numerical columns\n",
    "numerical_corr = coor[numerical_columns].corr()\n",
    "\n",
    "# Calculate correlation matrix for categorical columns\n",
    "#categorical_corr = tempdf[categorical_columns].corr()\n",
    "\n",
    "# Print correlation matrices\n",
    "print(\"Correlation Matrix for Numerical Columns:\")\n",
    "numerical_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Miscellaneous(Unwanted) columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Category', 'City', 'Country', 'Customer.ID',\n",
      "       'Customer.Name', 'Discount', 'Market', '记录数', 'Order.Date', 'Order.ID',\n",
      "       'Order.Priority', 'Product.ID', 'Product.Name', 'Profit', 'Quantity',\n",
      "       'Region', 'Row.ID', 'Sales', 'Segment', 'Ship.Date', 'Ship.Mode',\n",
      "       'Shipping.Cost', 'State', 'Sub.Category', 'Year', 'Market2', 'weeknum'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        36624.0\n",
       "1        37033.0\n",
       "2        31468.0\n",
       "3        31469.0\n",
       "4        32440.0\n",
       "          ...   \n",
       "51285    33646.0\n",
       "51286    33645.0\n",
       "51287    32321.0\n",
       "51288    35917.0\n",
       "51289    37371.0\n",
       "Name: Row.ID, Length: 51290, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf.pop(\"Unnamed: 0\") # Dosen't provide any useful information\n",
    "tempdf.pop(\"记录数\") # Dosen't provide any useful information\n",
    "tempdf.pop(\"Row.ID\") # Reduntant column that provides the row number\n",
    "tempdf.pop('Year')\n",
    "tempdf.pop('Market2')\n",
    "tempdf.pop('Sub.Category')\n",
    "print(tempdf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearraging the columns for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51290 entries, 0 to 51289\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Order.ID        50986 non-null  object \n",
      " 1   Order.Date      51085 non-null  object \n",
      " 2   weeknum         51290 non-null  int64  \n",
      " 3   Year            51178 non-null  float64\n",
      " 4   Ship.Date       50917 non-null  object \n",
      " 5   Order.Priority  51157 non-null  object \n",
      " 6   Ship.Mode       50822 non-null  object \n",
      " 7   Customer.ID     51064 non-null  object \n",
      " 8   Customer.Name   50864 non-null  object \n",
      " 9   Segment         50863 non-null  object \n",
      " 10  City            51044 non-null  object \n",
      " 11  State           50875 non-null  object \n",
      " 12  Country         50883 non-null  object \n",
      " 13  Region          50879 non-null  object \n",
      " 14  Product.ID      51000 non-null  object \n",
      " 15  Product.Name    51259 non-null  object \n",
      " 16  Category        51171 non-null  object \n",
      " 17  Sub.Category    51014 non-null  object \n",
      " 18  Quantity        51142 non-null  float64\n",
      " 19  Sales           51113 non-null  float64\n",
      " 20  Discount        50824 non-null  float64\n",
      " 21  Profit          50963 non-null  float64\n",
      " 22  Market          51068 non-null  object \n",
      " 23  Market2         51242 non-null  object \n",
      "dtypes: float64(5), int64(1), object(18)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    # Order Details\n",
    "    \"Order.ID\", \"Order.Date\", \"weeknum\", \"Ship.Date\", \"Order.Priority\", \"Ship.Mode\", \"Shipping.Cost\",\n",
    "    # Customer Details\n",
    "    \"Customer.ID\", \"Customer.Name\", \"Segment\",    \n",
    "    # Location Details\n",
    "    \"City\", \"State\", \"Country\",\"Region\",   \n",
    "    # Product Details\n",
    "    \"Product.ID\", \"Product.Name\", \"Category\",    \n",
    "    # Sales and Financials\n",
    "    \"Quantity\", \"Sales\", \"Discount\", \"Profit\",    \n",
    "    # Market Details\n",
    "    \"Market\"\n",
    "]\n",
    "tempdf=tempdf[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Datatype of Object to String for the concerning factors\n",
    "for i in tempdf.columns:\n",
    "    if(tempdf[i].dtypes=='object'):\n",
    "        tempdf[i]=tempdf[i].astype(\"string\")\n",
    "tempdf['Order.Date']=pd.to_datetime(tempdf['Order.Date'])\n",
    "tempdf['Ship.Date']=pd.to_datetime(tempdf['Ship.Date'])\n",
    "\n",
    "#setting the dataframe index to show number of observation and sorting w.r.t. Order.Date\n",
    "tempdf=tempdf.sort_values(by='Order.Date', ascending=False)\n",
    "tempdf.reset_index()\n",
    "tempdf.set_index(np.arange(0,len(tempdf)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate rows: 0\n",
      "Number of Observations after removing duplicates and rows with wrong Shipping Date: 50715\n",
      "Data lost after the above step: 1.12%\n"
     ]
    }
   ],
   "source": [
    "# Discarding observations where the shipping date is earlier than the order date\n",
    "before_cleaing=len(tempdf)\n",
    "tempdf = tempdf[tempdf['Ship.Date'] >= tempdf['Order.Date']]\n",
    "\n",
    "# Checking for duplicate entries\n",
    "print(f\"Number of Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Number of Observations after removing duplicates and rows with wrong Shipping Date: {len(tempdf)}\")\n",
    "print(f\"Data lost after the above step: {round((before_cleaing-len(tempdf))/before_cleaing*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market and Market2\n",
    "M1=tempdf[\"Market\"].dropna().unique().tolist()\n",
    "M2=tempdf[\"Market2\"].dropna().unique().tolist()\n",
    "M2.append(\"North America\")\n",
    "\n",
    "for i in range(len(M1)): \n",
    "    tempdf.loc[tempdf[\"Market\"].isna() & (tempdf[\"Market2\"]==M2[i]), \"Market\"] = M1[i]\n",
    "    tempdf.loc[tempdf[\"Market2\"].isna() & (tempdf[\"Market\"]==M1[i]), \"Market2\"] = M2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'Customer.ID'\n",
    "missing_id = tempdf[tempdf['Customer.ID'].isna()]\n",
    "\n",
    "# Find unique customer information in the DataFrame\n",
    "unique_id = tempdf[['Customer.ID', 'City', 'State', 'Country', 'Region', 'Customer.Name']].dropna()\n",
    "\n",
    "# Create a mapping for missing 'Customer.Name'\n",
    "mapping = unique_id.set_index(['Customer.Name', 'City', 'State', 'Country', 'Region'])['Customer.ID'].to_dict()\n",
    "\n",
    "# Apply the mapping to fill missing values in 'Customer.Name'\n",
    "tempdf['Customer.ID'] = tempdf.apply(\n",
    "    lambda row: mapping.get((row['Customer.Name'], row['City'], row['State'], row['Country'], row['Region']), row['Customer.ID']),\n",
    "    axis=1\n",
    ")\n",
    "print(tempdf['Customer.ID'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'Customer.Name'\n",
    "missing_names = tempdf[tempdf['Customer.Name'].isna()]\n",
    "\n",
    "# Find unique customer information in the DataFrame\n",
    "unique_customers = tempdf[['Customer.ID', 'City', 'State', 'Country', 'Region', 'Customer.Name']].dropna()\n",
    "\n",
    "# Create a mapping for missing 'Customer.Name'\n",
    "mapping = unique_customers.set_index(['Customer.ID', 'City', 'State', 'Country', 'Region'])['Customer.Name'].to_dict()\n",
    "\n",
    "# Apply the mapping to fill missing values in 'Customer.Name'\n",
    "tempdf['Customer.Name'] = tempdf.apply(\n",
    "    lambda row: mapping.get((row['Customer.ID'], row['City'], row['State'], row['Country'], row['Region']), row['Customer.Name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check the result\n",
    "print(tempdf['Customer.Name'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order.ID          301\n",
       "Order.Date          0\n",
       "weeknum             0\n",
       "Year              110\n",
       "Ship.Date           0\n",
       "Order.Priority    133\n",
       "Ship.Mode         463\n",
       "Customer.ID       224\n",
       "Customer.Name     423\n",
       "Segment           424\n",
       "City              244\n",
       "State             412\n",
       "Country           403\n",
       "Region            410\n",
       "Product.ID        285\n",
       "Product.Name       29\n",
       "Category          116\n",
       "Sub.Category      275\n",
       "Quantity          147\n",
       "Sales             177\n",
       "Discount          459\n",
       "Profit            323\n",
       "Market              0\n",
       "Market2             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Location data\n",
    "location=tempdf.loc[:,['City', 'State', 'Country', 'Region']].drop_duplicates()\n",
    "loc_u=location.dropna()\n",
    "tempdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order.ID          301\n",
      "Order.Date          0\n",
      "weeknum             0\n",
      "Year              110\n",
      "Ship.Date           0\n",
      "Order.Priority    133\n",
      "Ship.Mode         463\n",
      "Customer.ID       224\n",
      "Customer.Name     423\n",
      "Segment           424\n",
      "City              244\n",
      "State              14\n",
      "Country            10\n",
      "Region              9\n",
      "Product.ID        285\n",
      "Product.Name       29\n",
      "Category          116\n",
      "Sub.Category      275\n",
      "Quantity          147\n",
      "Sales             177\n",
      "Discount          459\n",
      "Profit            323\n",
      "Market              0\n",
      "Market2             0\n",
      "dtype: int64 50715\n"
     ]
    }
   ],
   "source": [
    "# Merge tempdf with location on 'City' and 'State'\n",
    "merged_df_Country = tempdf.merge(loc_u, on=['City', 'State', 'Region'], how='left', suffixes=('', '_loc'))\n",
    "merged_df_State = tempdf.merge(loc_u, on=['Country', 'City',  'Region'], how='left', suffixes=('', '_loc'))\n",
    "#merged_df_City = tempdf.merge(loc_u, on=['Country', 'State', 'Region'], how='left', suffixes=('', '_loc'))\n",
    "#merged_df_Region = tempdf.merge(loc_u, on=['Country', 'State', 'City'], how='left', suffixes=('', '_loc'))\n",
    "\n",
    "\n",
    "# Fill missing 'Country' values in tempdf with the values from loc_u\n",
    "tempdf['Country'] = tempdf['Country'].fillna(merged_df_Country['Country_loc'])\n",
    "tempdf['State'] = tempdf['State'].fillna(merged_df_State['State_loc'])\n",
    "#tempdf['City'] = tempdf['City'].fillna(merged_df_City['City_loc'])\n",
    "#tempdf['Region'] = tempdf['Region'].fillna(merged_df_Region['Region_loc'])\n",
    "\n",
    "\n",
    "# Check for missing values in 'Region'\n",
    "missing_region = tempdf[tempdf['Region'].isna()]\n",
    "unique_regions = tempdf[['Country', 'Region']].dropna()\n",
    "mapping = unique_regions.set_index(['Country'])['Region'].to_dict()\n",
    "tempdf['Region'] = tempdf.apply(\n",
    "    lambda row: mapping.get((row['Country']), row['Region']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "print(tempdf.isna().sum(), len(tempdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order Date\n",
    "#tempdf['Year'] = np.where(tempdf['Year'].isna(), pd.DatetimeIndex(tempdf['Order.Date']).year, tempdf['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data lost after cleaning: 1.46%\n",
      "Order.ID          298\n",
      "Order.Date          0\n",
      "weeknum             0\n",
      "Year                0\n",
      "Ship.Date           0\n",
      "Order.Priority    132\n",
      "Ship.Mode         456\n",
      "Customer.ID       220\n",
      "Customer.Name     420\n",
      "Segment           418\n",
      "City                0\n",
      "State              13\n",
      "Country            10\n",
      "Region              9\n",
      "Product.ID        283\n",
      "Product.Name       29\n",
      "Category          114\n",
      "Sub.Category      268\n",
      "Quantity          145\n",
      "Sales               0\n",
      "Discount          451\n",
      "Profit              0\n",
      "Market              0\n",
      "Market2             0\n",
      "dtype: int64 49973\n"
     ]
    }
   ],
   "source": [
    "before=len(tempdf)\n",
    "Cleaned_df=tempdf.dropna(subset=['Sales','Profit', 'City'])\n",
    "after=len(Cleaned_df)\n",
    "\n",
    "print(f\"Data lost after cleaning: {round((before-after)/before*100, 2)}%\")\n",
    "print(Cleaned_df.isna().sum(), len(Cleaned_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Cleaned DataFrame to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49973 entries, 0 to 51084\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Order.ID        49675 non-null  string        \n",
      " 1   Order.Date      49973 non-null  datetime64[ns]\n",
      " 2   weeknum         49973 non-null  int64         \n",
      " 3   Year            49973 non-null  float64       \n",
      " 4   Ship.Date       49973 non-null  datetime64[ns]\n",
      " 5   Order.Priority  49841 non-null  string        \n",
      " 6   Ship.Mode       49517 non-null  string        \n",
      " 7   Customer.ID     49753 non-null  string        \n",
      " 8   Customer.Name   49553 non-null  string        \n",
      " 9   Segment         49555 non-null  string        \n",
      " 10  City            49973 non-null  string        \n",
      " 11  State           49960 non-null  string        \n",
      " 12  Country         49963 non-null  string        \n",
      " 13  Region          49964 non-null  string        \n",
      " 14  Product.ID      49690 non-null  string        \n",
      " 15  Product.Name    49944 non-null  string        \n",
      " 16  Category        49859 non-null  string        \n",
      " 17  Sub.Category    49705 non-null  string        \n",
      " 18  Quantity        49828 non-null  float64       \n",
      " 19  Sales           49973 non-null  float64       \n",
      " 20  Discount        49522 non-null  float64       \n",
      " 21  Profit          49973 non-null  float64       \n",
      " 22  Market          49973 non-null  string        \n",
      " 23  Market2         49973 non-null  string        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), string(16)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "Cleaned_df['Segment']= Cleaned_df['Segment'].fillna(Cleaned_df['Segment'].mode()[0])\n",
    "Cleaned_df['Ship.Mode']= Cleaned_df['Ship.Mode'].fillna(Cleaned_df['Ship.Mode'].mode()[0])\n",
    "Cleaned_df['Order.Priority']= Cleaned_df['Order.Priority'].fillna(Cleaned_df['Order.Priority'].mode()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
